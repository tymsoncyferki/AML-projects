{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import bernoulli, multivariate_normal\n",
    "from feature_engine.selection import DropCorrelatedFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 1 - secom\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/179/secom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_secom = pd.read_csv(\"raw_data/secom/secom.data\", header=None, sep=' ')\n",
    "y_secom = pd.read_csv(\"raw_data/secom/secom_labels.data\", header=None, sep=' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_secom = y_secom.apply(lambda x: max(x,0))  # change -1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nans\n",
    "X_secom = X_secom.fillna(X_secom.mean())\n",
    "\n",
    "# drop correlated columns\n",
    "tr = DropCorrelatedFeatures(None, threshold=0.9)\n",
    "X_secom = tr.fit_transform(X_secom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    1463\n",
       "1     104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_secom.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset so number of features is at least 50% of number of instances\n",
    "new_n = X_secom.shape[1] * 2\n",
    "\n",
    "data = X_secom.copy()\n",
    "data[\"y\"] = y_secom\n",
    "\n",
    "y1 = data[data[\"y\"] == 1]\n",
    "y0 = data[data[\"y\"] == 0]\n",
    "\n",
    "# we keep all rows with y=1, as data is highly imbalanced and we want to balance it a litle bit\n",
    "rest_n = new_n - len(y1)\n",
    "y0_sample = y0.sample(n=rest_n, random_state=42)\n",
    "\n",
    "subset = pd.concat([y1, y0_sample]).sample(frac=1).reset_index(drop=True)  # sample to randomize order of rows\n",
    "y_subset = subset[\"y\"]\n",
    "X_subset = subset.drop(columns=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances x features: (768, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    664\n",
       "1    104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"instances x features:\", X_subset.shape)\n",
    "y_subset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv(\"data/secom.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset 2\n",
    "\n",
    "propozycja: https://archive.ics.uci.edu/dataset/604/gait+classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(p=0.5, n=1000, d=10, g=0.5) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates synthethic dataset\n",
    "\n",
    "    Args: \n",
    "        p: prior probability for y=1\n",
    "        n: number of instances\n",
    "        d: number of features\n",
    "        g: param for cov matrix\n",
    "\n",
    "    Returns:\n",
    "        X, y\n",
    "    \"\"\"\n",
    "    y = bernoulli.rvs(p, size=n)\n",
    "    \n",
    "    # mean vectors\n",
    "    m0 = np.zeros(d)\n",
    "    m1 = np.array([1/(i+1) for i in range(d)])\n",
    "\n",
    "    # cov matrix\n",
    "    S = np.array([[g**abs(i - j) for j in range(d)] for i in range(d)])\n",
    "\n",
    "    X = np.zeros((n, d))\n",
    "    X[y==0] = multivariate_normal.rvs(mean = m0, cov=S, size=len(X[y==0]))\n",
    "    X[y==1] = multivariate_normal.rvs(mean = m1, cov=S, size=len(X[y==1]))   \n",
    "\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
