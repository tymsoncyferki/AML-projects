{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane zostały zapisane w pliku 'data/arrhythmia.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Wczytanie danych\n",
    "data = pd.read_csv(\"raw_data/arrhythmia/arrhythmia.data\", header=None, na_values='?')\n",
    "\n",
    "# Przypisanie ostatniej kolumny jako target\n",
    "data.rename(columns={data.columns[-1]: 'target'}, inplace=True)\n",
    "\n",
    "# Konwersja klas na binarne:\n",
    "# 0 (Normalny), 1 (wszystkie inne)\n",
    "data['target'] = data['target'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Tworzenie katalogu 'data', jeśli nie istnieje\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Zapisanie pełnych danych do CSV\n",
    "data.to_csv('data/arrhythmia.csv', index=False)\n",
    "print(\"Dane zostały zapisane w pliku 'data/arrhythmia.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela danych treningowych (pierwsze 5 wierszy):\n",
      "   0  1  2  3  4  5  6  7  8    9  ...  19991  19992  19993  19994  19995  \\\n",
      "0  0  0  0  0  0  0  0  0  0  105  ...      0      0      0      0      0   \n",
      "1  0  0  0  0  0  0  0  0  0    0  ...      0      0      0      0      0   \n",
      "2  0  0  0  0  0  0  0  0  0    0  ...      0      0      0      0      0   \n",
      "3  0  0  0  0  0  0  0  0  0    0  ...      0      0      0      0      0   \n",
      "4  0  0  0  0  0  0  0  0  0    0  ...      0      0      0      0      0   \n",
      "\n",
      "   19996  19997  19998  19999  target  \n",
      "0      0      0     56      0       1  \n",
      "1      0      0      0      0      -1  \n",
      "2      0      0      0      0       1  \n",
      "3      0      0      0      0      -1  \n",
      "4      0      0      0      0       1  \n",
      "\n",
      "[5 rows x 20001 columns]\n",
      "\n",
      "Podstawowe statystyki danych treningowych:\n",
      "           0      1      2           3      4           5      6           7  \\\n",
      "count  300.0  300.0  300.0  300.000000  300.0  300.000000  300.0  300.000000   \n",
      "mean     0.0    0.0    0.0    0.906667    0.0    0.386667    0.0    0.530000   \n",
      "std      0.0    0.0    0.0   11.581814    0.0    6.697263    0.0    7.315336   \n",
      "min      0.0    0.0    0.0    0.000000    0.0    0.000000    0.0    0.000000   \n",
      "25%      0.0    0.0    0.0    0.000000    0.0    0.000000    0.0    0.000000   \n",
      "50%      0.0    0.0    0.0    0.000000    0.0    0.000000    0.0    0.000000   \n",
      "75%      0.0    0.0    0.0    0.000000    0.0    0.000000    0.0    0.000000   \n",
      "max      0.0    0.0    0.0  177.000000    0.0  116.000000    0.0  121.000000   \n",
      "\n",
      "                8           9  ...      19991  19992  19993  19994  \\\n",
      "count  300.000000  300.000000  ...  300.00000  300.0  300.0  300.0   \n",
      "mean     0.493333    0.350000  ...    0.45000    0.0    0.0    0.0   \n",
      "std      6.087156    6.062178  ...    5.56874    0.0    0.0    0.0   \n",
      "min      0.000000    0.000000  ...    0.00000    0.0    0.0    0.0   \n",
      "25%      0.000000    0.000000  ...    0.00000    0.0    0.0    0.0   \n",
      "50%      0.000000    0.000000  ...    0.00000    0.0    0.0    0.0   \n",
      "75%      0.000000    0.000000  ...    0.00000    0.0    0.0    0.0   \n",
      "max     84.000000  105.000000  ...   78.00000    0.0    0.0    0.0   \n",
      "\n",
      "            19995       19996  19997       19998  19999      target  \n",
      "count  300.000000  300.000000  300.0  300.000000  300.0  300.000000  \n",
      "mean     1.110000    0.093333    0.0    1.323333    0.0    0.000000  \n",
      "std     11.454048    1.616581    0.0   11.073128    0.0    1.001671  \n",
      "min      0.000000    0.000000    0.0    0.000000    0.0   -1.000000  \n",
      "25%      0.000000    0.000000    0.0    0.000000    0.0   -1.000000  \n",
      "50%      0.000000    0.000000    0.0    0.000000    0.0    0.000000  \n",
      "75%      0.000000    0.000000    0.0    0.000000    0.0    1.000000  \n",
      "max    139.000000   28.000000    0.0  148.000000    0.0    1.000000  \n",
      "\n",
      "[8 rows x 20001 columns]\n",
      "\n",
      "Unikalne klasy w danych treningowych:\n",
      "[ 1 -1]\n",
      "Dane zostały zapisane w pliku 'data/dexter.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Funkcja do wczytywania danych Dexter (sparse format)\n",
    "def load_dexter_data_sparse(filepath_data, filepath_labels, num_features=20000):\n",
    "    rows, cols, vals = [], [], []\n",
    "    with open(filepath_data, 'r') as file:\n",
    "        for row_idx, line in enumerate(file):\n",
    "            elements = line.strip().split()\n",
    "            for el in elements:\n",
    "                col_idx, val = el.split(\":\")\n",
    "                rows.append(row_idx)\n",
    "                cols.append(int(col_idx)-1)  # indeksy zaczynają się od 1\n",
    "                vals.append(int(val))\n",
    "\n",
    "    X_sparse = csr_matrix((vals, (rows, cols)), shape=(row_idx+1, num_features))\n",
    "    X = pd.DataFrame(X_sparse.toarray())\n",
    "\n",
    "    y = pd.read_csv(filepath_labels, header=None, names=['target'])\n",
    "    \n",
    "    # Połączenie cech i etykiet w jedną tabelę\n",
    "    df = X.copy()\n",
    "    df['target'] = y['target']\n",
    "    return df\n",
    "\n",
    "# Ścieżki do plików\n",
    "train_data_path = 'raw_data/dexter/DEXTER/dexter_train.data'\n",
    "train_labels_path = 'raw_data/dexter/DEXTER/dexter_train.labels'\n",
    "\n",
    "# Wczytanie danych\n",
    "dexter_df = load_dexter_data_sparse(train_data_path, train_labels_path)\n",
    "\n",
    "# Wyświetlenie pierwszych 5 wierszy danych treningowych\n",
    "print(\"Tabela danych treningowych (pierwsze 5 wierszy):\")\n",
    "print(dexter_df.head())\n",
    "\n",
    "# Podstawowe statystyki dla danych treningowych\n",
    "print(\"\\nPodstawowe statystyki danych treningowych:\")\n",
    "print(dexter_df.describe())\n",
    "\n",
    "# Liczba unikalnych klas\n",
    "print(\"\\nUnikalne klasy w danych treningowych:\")\n",
    "print(dexter_df['target'].unique())\n",
    "\n",
    "# Tworzenie katalogu 'data', jeśli nie istnieje\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Zapis danych do CSV\n",
    "dexter_df.to_csv('data/dexter.csv', index=False)\n",
    "print(\"Dane zostały zapisane w pliku 'data/dexter.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Wyniki dla Arrhythmia - bez regularyzacji ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74        61\n",
      "           1       0.69      0.73      0.71        52\n",
      "\n",
      "    accuracy                           0.73       113\n",
      "   macro avg       0.72      0.73      0.72       113\n",
      "weighted avg       0.73      0.73      0.73       113\n",
      "\n",
      "Macierz pomyłek:\n",
      "[[44 17]\n",
      " [14 38]]\n",
      "\n",
      "=== Wyniki dla Arrhythmia - z regularyzacją (L2) ===\n",
      "Najlepszy parametr C: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        61\n",
      "           1       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.81       113\n",
      "   macro avg       0.81      0.81      0.81       113\n",
      "weighted avg       0.81      0.81      0.81       113\n",
      "\n",
      "Macierz pomyłek:\n",
      "[[52  9]\n",
      " [12 40]]\n",
      "\n",
      "=== Wyniki dla Dexter - bez regularyzacji ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.87      0.92        38\n",
      "           1       0.88      0.97      0.92        37\n",
      "\n",
      "    accuracy                           0.92        75\n",
      "   macro avg       0.92      0.92      0.92        75\n",
      "weighted avg       0.92      0.92      0.92        75\n",
      "\n",
      "Macierz pomyłek:\n",
      "[[33  5]\n",
      " [ 1 36]]\n",
      "\n",
      "=== Wyniki dla Dexter - z regularyzacją (L2) ===\n",
      "Najlepszy parametr C: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.87      0.92        38\n",
      "           1       0.88      0.97      0.92        37\n",
      "\n",
      "    accuracy                           0.92        75\n",
      "   macro avg       0.92      0.92      0.92        75\n",
      "weighted avg       0.92      0.92      0.92        75\n",
      "\n",
      "Macierz pomyłek:\n",
      "[[33  5]\n",
      " [ 1 36]]\n"
     ]
    }
   ],
   "source": [
    "# Arrhythmia\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Funkcja do wczytania i przygotowania danych\n",
    "def load_and_prepare_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Podział na cechy i target\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    \n",
    "    # Uzupełnianie brakujących wartości średnią\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Standaryzacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "# Ścieżki do plików\n",
    "arrhythmia_path = 'data/arrhythmia.csv'\n",
    "dexter_path = 'data/dexter.csv'\n",
    "\n",
    "# Wczytanie i przygotowanie danych\n",
    "X_arrhythmia, y_arrhythmia = load_and_prepare_data(arrhythmia_path)\n",
    "X_dexter, y_dexter = load_and_prepare_data(dexter_path)\n",
    "\n",
    "# Funkcja do trenowania i oceny regresji logistycznej\n",
    "def train_and_evaluate(X, y, dataset_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    \n",
    "    # Regresja logistyczna bez regularyzacji\n",
    "    model_no_reg = LogisticRegression(penalty=None, max_iter=1000)\n",
    "    model_no_reg.fit(X_train, y_train)\n",
    "    y_pred_no_reg = model_no_reg.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n=== Wyniki dla {dataset_name} - bez regularyzacji ===\")\n",
    "    print(classification_report(y_test, y_pred_no_reg))\n",
    "    print(\"Macierz pomyłek:\")\n",
    "    print(confusion_matrix(y_test, y_pred_no_reg))\n",
    "    \n",
    "    # Regresja logistyczna z regularyzacją L2 (GridSearchCV dla parametru C)\n",
    "    param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    grid = GridSearchCV(LogisticRegression(max_iter=1000, penalty='l2'), param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred_reg = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n=== Wyniki dla {dataset_name} - z regularyzacją (L2) ===\")\n",
    "    print(\"Najlepszy parametr C:\", grid.best_params_['C'])\n",
    "    print(classification_report(y_test, y_pred_reg))\n",
    "    print(\"Macierz pomyłek:\")\n",
    "    print(confusion_matrix(y_test, y_pred_reg))\n",
    "\n",
    "# Trening i ocena dla obu zbiorów danych\n",
    "train_and_evaluate(X_arrhythmia, y_arrhythmia, \"Arrhythmia\")\n",
    "train_and_evaluate(X_dexter, y_dexter, \"Dexter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
