{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514f1ec8681587fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:14.598080Z",
     "start_time": "2025-03-25T21:32:14.594091Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score, \n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:19:04.387739Z",
     "start_time": "2025-03-25T22:19:04.365796Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogRegCCD:\n",
    "    def __init__(self, lambda_min=1e-4, lambda_max=1.0, num_lambdas=100, alpha=1.0):\n",
    "        self.lambda_min = lambda_min\n",
    "        self.lambda_max = lambda_max\n",
    "        self.num_lambdas = num_lambdas\n",
    "        self.alpha = alpha\n",
    "        self.coefficients = None\n",
    "        self.lambdas = np.logspace(np.log10(lambda_max), np.log10(lambda_min), num_lambdas)\n",
    "        self.best_lambda = None\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X_train, y_train, lmbda=None):\n",
    "        if lmbda is None:\n",
    "            lmbda = self.lambda_min\n",
    "\n",
    "        n_samples, n_features = X_train.shape\n",
    "        self.coefficients = np.zeros(n_features + 1)\n",
    "\n",
    "        for _ in range(100):\n",
    "            intercept = self.coefficients[0]\n",
    "            weights = self.coefficients[1:]\n",
    "\n",
    "            for j in range(n_features):\n",
    "                partial_residual = y_train - self._sigmoid(np.dot(np.delete(X_train, j, axis=1), np.delete(weights, j)) + intercept)\n",
    "                gradient = np.dot(X_train[:, j].T, partial_residual.T) / n_samples\n",
    "                l1_penalty = self.alpha * lmbda\n",
    "                l2_penalty = (1 - self.alpha) * lmbda\n",
    "                soft_threshold = np.sign(gradient) * max(0.0, abs(gradient) - l1_penalty)\n",
    "                weights[j] = soft_threshold.item() / (1 + l2_penalty)\n",
    "\n",
    "            intercept += np.mean(y_train - self._sigmoid(np.dot(X_train, weights) + intercept))\n",
    "\n",
    "            self.coefficients[0] = intercept\n",
    "            self.coefficients[1:] = weights\n",
    "\n",
    "    def validate(self, X_valid, y_valid, measure=\"f1\"):\n",
    "        probabilities = self.predict_proba(X_valid)\n",
    "        predictions = (probabilities >= 0.5).astype(int)\n",
    "        \n",
    "        if measure == \"precision\":\n",
    "            return precision_score(y_valid, predictions)\n",
    "        elif measure == \"recall\":\n",
    "            return recall_score(y_valid, predictions)\n",
    "        elif measure == \"f1\":\n",
    "            return f1_score(y_valid, predictions)\n",
    "        elif measure == \"balanced_accuracy\":\n",
    "            return balanced_accuracy_score(y_valid, predictions)\n",
    "        elif measure == \"roc_auc\":\n",
    "            return roc_auc_score(y_valid, probabilities)\n",
    "        elif measure == \"pr_auc\":\n",
    "            return average_precision_score(y_valid, probabilities)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported measure: {}\".format(measure))\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return np.asarray(self._sigmoid(np.dot(X_test, self.coefficients[1:]) + self.coefficients[0]).T).reshape(-1)\n",
    "\n",
    "    def optimize_lambda(self, X_train, y_train, X_valid, y_valid, measure=\"f1\"):\n",
    "        best_score = -np.inf\n",
    "        for lmbda in self.lambdas:\n",
    "            print(f'Fitting lmbda: {lmbda}')\n",
    "            self.fit(X_train, y_train, lmbda)\n",
    "            score = self.validate(X_valid, y_valid, measure=measure)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                self.best_lambda = lmbda\n",
    "\n",
    "        return self.best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763e24f97c66ab31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:07.453581Z",
     "start_time": "2025-03-25T21:32:07.323899Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b90a58820a0f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:18.905356Z",
     "start_time": "2025-03-25T21:32:18.887549Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.asmatrix(df.drop(columns='target'))\n",
    "y = np.asarray(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700824f16e3542c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:42:28.976219Z",
     "start_time": "2025-03-25T21:42:28.964224Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae43775448d45411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:26:14.600432Z",
     "start_time": "2025-03-25T22:19:11.651349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.35938136638046275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.1291549665014884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.046415888336127795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.016681005372000592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.005994842503189409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0021544346900318843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0007742636826811277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0002782559402207126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "/var/folders/ry/kcmcwh_95_jgg3sg1zp_pp5m0000gn/T/ipykernel_2981/2540017061.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegCCD F1 Score: 0.8448\n"
     ]
    }
   ],
   "source": [
    "ccd_model = LogRegCCD(num_lambdas=10)\n",
    "ccd_model.optimize_lambda(X_train, y_train, X_test, y_test, measure=\"f1\")\n",
    "ccd_model.fit(X_train, y_train, ccd_model.best_lambda)\n",
    "\n",
    "ccd_probs = ccd_model.predict_proba(X_test)\n",
    "ccd_preds = (ccd_probs >= 0.5).astype(int)\n",
    "ccd_f1 = f1_score(y_test, ccd_preds)\n",
    "print(f\"LogRegCCD F1 Score: {ccd_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a0453a00b0f898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:15:40.078007Z",
     "start_time": "2025-03-25T22:15:40.029012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikolajmroz/Developer/AML-projects/Project1/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, penalty='elasticnet', solver='saga', l1_ratio=0.9)\n",
    "logreg.fit(np.asarray(X_train), y_train)\n",
    "sklearn_preds = logreg.predict(np.asarray(X_test))\n",
    "sklearn_f1 = f1_score(y_test, sklearn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865651142d3a377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:15:35.387283Z",
     "start_time": "2025-03-25T22:15:35.374307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324324324324325"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
