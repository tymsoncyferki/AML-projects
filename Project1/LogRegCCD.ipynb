{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:14.598080Z",
     "start_time": "2025-03-25T21:32:14.594091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score, \n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ],
   "id": "514f1ec8681587fa",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:19:04.387739Z",
     "start_time": "2025-03-25T22:19:04.365796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LogRegCCD:\n",
    "    def __init__(self, lambda_min=1e-4, lambda_max=1.0, num_lambdas=100, alpha=1.0):\n",
    "        self.lambda_min = lambda_min\n",
    "        self.lambda_max = lambda_max\n",
    "        self.num_lambdas = num_lambdas\n",
    "        self.alpha = alpha\n",
    "        self.coefficients = None\n",
    "        self.lambdas = np.logspace(np.log10(lambda_max), np.log10(lambda_min), num_lambdas)\n",
    "        self.best_lambda = None\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X_train, y_train, lmbda=None):\n",
    "        if lmbda is None:\n",
    "            lmbda = self.lambda_min\n",
    "\n",
    "        n_samples, n_features = X_train.shape\n",
    "        self.coefficients = np.zeros(n_features + 1)\n",
    "\n",
    "        for _ in range(100):\n",
    "            intercept = self.coefficients[0]\n",
    "            weights = self.coefficients[1:]\n",
    "\n",
    "            for j in range(n_features):\n",
    "                partial_residual = y_train - self._sigmoid(np.dot(np.delete(X_train, j, axis=1), np.delete(weights, j)) + intercept)\n",
    "                gradient = np.dot(X_train[:, j].T, partial_residual.T) / n_samples\n",
    "                l1_penalty = self.alpha * lmbda\n",
    "                l2_penalty = (1 - self.alpha) * lmbda\n",
    "                soft_threshold = np.sign(gradient) * max(0.0, abs(gradient) - l1_penalty)\n",
    "                weights[j] = soft_threshold.item() / (1 + l2_penalty)\n",
    "\n",
    "            intercept += np.mean(y_train - self._sigmoid(np.dot(X_train, weights) + intercept))\n",
    "\n",
    "            self.coefficients[0] = intercept\n",
    "            self.coefficients[1:] = weights\n",
    "\n",
    "    def validate(self, X_valid, y_valid, measure=\"f1\"):\n",
    "        probabilities = self.predict_proba(X_valid)\n",
    "        predictions = (probabilities >= 0.5).astype(int)\n",
    "        \n",
    "        if measure == \"precision\":\n",
    "            return precision_score(y_valid, predictions)\n",
    "        elif measure == \"recall\":\n",
    "            return recall_score(y_valid, predictions)\n",
    "        elif measure == \"f1\":\n",
    "            return f1_score(y_valid, predictions)\n",
    "        elif measure == \"balanced_accuracy\":\n",
    "            return balanced_accuracy_score(y_valid, predictions)\n",
    "        elif measure == \"roc_auc\":\n",
    "            return roc_auc_score(y_valid, probabilities)\n",
    "        elif measure == \"pr_auc\":\n",
    "            return average_precision_score(y_valid, probabilities)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported measure: {}\".format(measure))\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return np.asarray(self._sigmoid(np.dot(X_test, self.coefficients[1:]) + self.coefficients[0]).T).reshape(-1)\n",
    "\n",
    "    def optimize_lambda(self, X_train, y_train, X_valid, y_valid, measure=\"f1\"):\n",
    "        best_score = -np.inf\n",
    "        for lmbda in self.lambdas:\n",
    "            print(f'Fitting lmbda: {lmbda}')\n",
    "            self.fit(X_train, y_train, lmbda)\n",
    "            score = self.validate(X_valid, y_valid, measure=measure)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                self.best_lambda = lmbda\n",
    "\n",
    "        return self.best_lambda"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:07.453581Z",
     "start_time": "2025-03-25T21:32:07.323899Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('./Project1/data/speech.csv')",
   "id": "763e24f97c66ab31",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:32:18.905356Z",
     "start_time": "2025-03-25T21:32:18.887549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.asmatrix(df.drop(columns='target'))\n",
    "y = np.asarray(df['target'])"
   ],
   "id": "b9b90a58820a0f92",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T21:42:28.976219Z",
     "start_time": "2025-03-25T21:42:28.964224Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)",
   "id": "700824f16e3542c5",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:26:14.600432Z",
     "start_time": "2025-03-25T22:19:11.651349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ccd_model = LogRegCCD(num_lambdas=10)\n",
    "ccd_model.optimize_lambda(X_train, y_train, X_test, y_test, measure=\"f1\")\n",
    "ccd_model.fit(X_train, y_train, ccd_model.best_lambda)\n",
    "\n",
    "ccd_probs = ccd_model.predict_proba(X_test)\n",
    "ccd_preds = (ccd_probs >= 0.5).astype(int)\n",
    "ccd_f1 = f1_score(y_test, ccd_preds)\n",
    "print(f\"LogRegCCD F1 Score: {ccd_f1:.4f}\")"
   ],
   "id": "ae43775448d45411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.35938136638046275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.1291549665014884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.046415888336127795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.016681005372000592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.005994842503189409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0021544346900318843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0007742636826811277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0002782559402207126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting lmbda: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n",
      "C:\\Users\\krzys\\AppData\\Local\\Temp\\ipykernel_4928\\4283249741.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegCCD F1 Score: 0.8448\n"
     ]
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:15:40.078007Z",
     "start_time": "2025-03-25T22:15:40.029012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logreg = LogisticRegression(max_iter=1000, penalty='elasticnet', solver='saga', l1_ratio=0.9)\n",
    "logreg.fit(np.asarray(X_train), y_train)\n",
    "sklearn_preds = logreg.predict(np.asarray(X_test))\n",
    "sklearn_f1 = f1_score(y_test, sklearn_preds)"
   ],
   "id": "82a0453a00b0f898",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "l1_ratio must be specified when penalty is elasticnet.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[158], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m logreg \u001B[38;5;241m=\u001B[39m LogisticRegression(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m, solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mlogreg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m sklearn_preds \u001B[38;5;241m=\u001B[39m logreg\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39masarray(X_test))\n\u001B[0;32m      4\u001B[0m sklearn_f1 \u001B[38;5;241m=\u001B[39m f1_score(y_test, sklearn_preds)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1204\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1197\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1199\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1200\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[0;32m   1201\u001B[0m     )\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1204\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio must be specified when penalty is elasticnet.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mC \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:  \u001B[38;5;66;03m# default values\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: l1_ratio must be specified when penalty is elasticnet."
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T22:15:35.387283Z",
     "start_time": "2025-03-25T22:15:35.374307Z"
    }
   },
   "cell_type": "code",
   "source": "sklearn_f1",
   "id": "c865651142d3a377",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324324324324325"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
