{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T16:27:24.268556Z",
     "start_time": "2025-05-18T16:27:24.262486Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import custom_score, load_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T17:52:43.102612Z",
     "start_time": "2025-05-18T17:52:43.086273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def backward_forward_selection(X, y, initial_n, p_thresh=0.05, random_state=42, n_splits=5, add_flg=False, locked_features=None):\n",
    "    np.random.seed(random_state)\n",
    "    n_samples, n_features = X.shape\n",
    "    all_indices = list(range(n_features))\n",
    "\n",
    "    if locked_features is None:\n",
    "        locked_features = []\n",
    "\n",
    "    selected = list(np.random.choice(all_indices, size=initial_n, replace=False))\n",
    "\n",
    "    selected = list(set(selected + locked_features))\n",
    "    remaining = list(set(all_indices) - set(selected))\n",
    "\n",
    "    print(f\"Initially selected {len(selected)} features (locked: {len(locked_features)}).\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    def fit_model_cv(feature_indices):\n",
    "        scores = []\n",
    "        accs = []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X_scaled, y):\n",
    "            X_train_fold = X_scaled[train_idx][:, feature_indices]\n",
    "            y_train_fold = y[train_idx]\n",
    "            X_test_fold = X_scaled[test_idx][:, feature_indices]\n",
    "            y_test_fold = y[test_idx]\n",
    "\n",
    "            X_train_fold = sm.add_constant(X_train_fold, has_constant='add')\n",
    "            X_test_fold = sm.add_constant(X_test_fold, has_constant='add')\n",
    "\n",
    "            try:\n",
    "                model = sm.Logit(y_train_fold, X_train_fold).fit(disp=0)\n",
    "                y_pred = model.predict(X_test_fold)\n",
    "                score = custom_score(y_test_fold, y_pred, len(feature_indices))\n",
    "                acc = accuracy_score(y_test_fold, np.round(y_pred))\n",
    "                scores.append(score)\n",
    "                accs.append(acc)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return None, -np.inf, 0.0\n",
    "\n",
    "        return model, np.mean(scores), np.mean(accs)\n",
    "\n",
    "    model, best_score, acc = fit_model_cv(selected)\n",
    "    print(f\"Initial custom score: {best_score:.4f}\")\n",
    "    print(f\"Initial accuracy: {acc:.4f}\")\n",
    "\n",
    "    improved = True\n",
    "    iteration = 0\n",
    "\n",
    "    while improved:\n",
    "        improved = False\n",
    "        iteration += 1\n",
    "        print(f\"\\nIteration {iteration}\")\n",
    "\n",
    "        try:\n",
    "            pvalues = model.pvalues[1:]  # skip constant\n",
    "        except:\n",
    "            pvalues = np.ones(len(selected))\n",
    "\n",
    "        for i, feature in enumerate(selected.copy()):\n",
    "            if feature in locked_features:\n",
    "                continue  # skip locked features\n",
    "\n",
    "            if pvalues[i] > p_thresh:\n",
    "                trial_selected = selected.copy()\n",
    "                trial_selected.remove(feature)\n",
    "                trial_model, trial_score, trial_acc = fit_model_cv(trial_selected)\n",
    "                if trial_score > best_score:\n",
    "                    print(f\"Removed feature {feature} (better score: {trial_score:.4f}), features: {len(trial_selected)}, acc: {trial_acc:.4f}\")\n",
    "                    selected = trial_selected\n",
    "                    if add_flg:\n",
    "                        remaining.append(feature)\n",
    "                    model = trial_model\n",
    "                    best_score = trial_score\n",
    "                    improved = True\n",
    "                    break\n",
    "\n",
    "        for feature in remaining.copy():\n",
    "            trial_selected = selected + [feature]\n",
    "            trial_model, trial_score, trial_acc = fit_model_cv(trial_selected)\n",
    "            if trial_model is not None:\n",
    "                pval_index = trial_selected.index(feature) + 1\n",
    "                try:\n",
    "                    pval = trial_model.pvalues[pval_index]\n",
    "                except:\n",
    "                    pval = 1.0\n",
    "                if pval < p_thresh and trial_score > best_score:\n",
    "                    print(f\"Added feature {feature} (p={pval:.4f}) (better score: {trial_score:.4f}), features: {len(trial_selected)}, acc: {trial_acc:.4f}\")\n",
    "                    selected = trial_selected\n",
    "                    remaining.remove(feature)\n",
    "                    model = trial_model\n",
    "                    best_score = trial_score\n",
    "                    improved = True\n",
    "                    break\n",
    "\n",
    "    print(f\"\\nSelection finished. Final number of features: {len(selected)}. Final score: {best_score:.4f}\")\n",
    "    return selected, model, best_score\n"
   ],
   "id": "ad3d00cabd497c09",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-18T18:26:11.813944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = load_data('x_train.txt')\n",
    "y_train = load_data('y_train.txt')\n",
    "locked = [0, 2]\n",
    "\n",
    "X = X_train.to_numpy()\n",
    "y = y_train[0].to_numpy()\n",
    "\n",
    "selected_features, final_model, final_score = backward_forward_selection(X, y, 100, p_thresh=0.03, locked_features=locked)\n",
    "\n",
    "print(\"Wybrane zmienne:\", selected_features)\n",
    "print(\"Ostateczny score:\", final_score)"
   ],
   "id": "937999322480120c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially selected 100 features (locked: 2).\n",
      "Initial custom score: -12900.0000\n",
      "Initial accuracy: 0.6762\n",
      "\n",
      "Iteration 1\n",
      "Removed feature 9 (better score: -12690.0000), features: 99, acc: 0.6770\n",
      "\n",
      "Iteration 2\n",
      "Removed feature 11 (better score: -12440.0000), features: 98, acc: 0.6784\n",
      "\n",
      "Iteration 3\n",
      "Removed feature 15 (better score: -12260.0000), features: 97, acc: 0.6796\n",
      "\n",
      "Iteration 4\n",
      "Removed feature 18 (better score: -12040.0000), features: 96, acc: 0.6784\n",
      "\n",
      "Iteration 5\n",
      "Removed feature 22 (better score: -11840.0000), features: 95, acc: 0.6792\n",
      "\n",
      "Iteration 6\n",
      "Removed feature 30 (better score: -11650.0000), features: 94, acc: 0.6784\n",
      "\n",
      "Iteration 7\n",
      "Removed feature 33 (better score: -11480.0000), features: 93, acc: 0.6796\n",
      "\n",
      "Iteration 8\n",
      "Removed feature 39 (better score: -11260.0000), features: 92, acc: 0.6790\n",
      "\n",
      "Iteration 9\n",
      "Removed feature 46 (better score: -11040.0000), features: 91, acc: 0.6808\n",
      "\n",
      "Iteration 10\n",
      "Removed feature 55 (better score: -10870.0000), features: 90, acc: 0.6806\n",
      "\n",
      "Iteration 11\n",
      "Removed feature 63 (better score: -10660.0000), features: 89, acc: 0.6802\n",
      "\n",
      "Iteration 12\n",
      "Removed feature 68 (better score: -10430.0000), features: 88, acc: 0.6808\n",
      "\n",
      "Iteration 13\n",
      "Removed feature 69 (better score: -10250.0000), features: 87, acc: 0.6804\n",
      "\n",
      "Iteration 14\n",
      "Removed feature 70 (better score: -10080.0000), features: 86, acc: 0.6810\n",
      "\n",
      "Iteration 15\n",
      "Removed feature 72 (better score: -9840.0000), features: 85, acc: 0.6806\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m X = X_train.to_numpy()\n\u001B[32m      6\u001B[39m y = y_train[\u001B[32m0\u001B[39m].to_numpy()\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m selected_features, final_model, final_score = \u001B[43mbackward_forward_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_thresh\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.03\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocked_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocked\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mWybrane zmienne:\u001B[39m\u001B[33m\"\u001B[39m, selected_features)\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mOstateczny score:\u001B[39m\u001B[33m\"\u001B[39m, final_score)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 90\u001B[39m, in \u001B[36mbackward_forward_selection\u001B[39m\u001B[34m(X, y, initial_n, p_thresh, random_state, n_splits, add_flg, locked_features)\u001B[39m\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m remaining.copy():\n\u001B[32m     89\u001B[39m     trial_selected = selected + [feature]\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     trial_model, trial_score, trial_acc = \u001B[43mfit_model_cv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial_selected\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     91\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m trial_model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     92\u001B[39m         pval_index = trial_selected.index(feature) + \u001B[32m1\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mbackward_forward_selection.<locals>.fit_model_cv\u001B[39m\u001B[34m(feature_indices)\u001B[39m\n\u001B[32m     30\u001B[39m X_train_fold = X_scaled[train_idx][:, feature_indices]\n\u001B[32m     31\u001B[39m y_train_fold = y[train_idx]\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m X_test_fold = \u001B[43mX_scaled\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_indices\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     33\u001B[39m y_test_fold = y[test_idx]\n\u001B[32m     35\u001B[39m X_train_fold = sm.add_constant(X_train_fold, has_constant=\u001B[33m'\u001B[39m\u001B[33madd\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
